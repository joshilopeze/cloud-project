{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "import tensorflow as tf\r\n",
                "import numpy as np\r\n",
                "import tensorflow_datasets as tfds\r\n",
                "import matplotlib.pyplot as plt"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "datos, metadatos = tfds.load('fashion_mnist', as_supervised=True, with_info=True)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "#metadatos"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "source": [
                "datos_entrenamiento, datos_pruebas= datos ['train'], datos['test']"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "nombres_clases = metadatos.features['label'].names"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "source": [
                "def normalizar(imagenes, etiquetas):\r\n",
                "  imagenes = tf.cast(imagenes, tf.float32)\r\n",
                "  imagenes /= 255 \r\n",
                "  #0 y 1 unicamente\r\n",
                "  return imagenes, etiquetas\r\n",
                "\r\n",
                "#Normalizar los datos de entrenamiento y pruebas con la funcion que hicimos\r\n",
                "datos_entrenamiento = datos_entrenamiento.map(normalizar)\r\n",
                "datos_pruebas = datos_pruebas.map(normalizar)\r\n",
                "\r\n",
                "#Agregar a cache (usar memoria en lugar de disco, entrenamiento mas rapido)\r\n",
                "datos_entrenamiento = datos_entrenamiento.cache()\r\n",
                "datos_pruebas = datos_pruebas.cache()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "#plt.figure(figsize=(10,10))\r\n",
                "#for i, (imagen, etiqueta) in enumerate(datos_entrenamiento.take(25)):\r\n",
                "#  imagen = imagen.numpy().reshape((28,28))\r\n",
                "#  plt.subplot(5,5,i+1)\r\n",
                "#  plt.xticks([])\r\n",
                "#  plt.yticks([])\r\n",
                "#  plt.grid(False)\r\n",
                "#  plt.imshow(imagen, cmap=plt.cm.binary)\r\n",
                "#  plt.xlabel(nombres_clases[etiqueta])\r\n",
                "#plt.show()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "source": [
                "modelo = tf.keras.Sequential([\r\n",
                "  tf.keras.layers.Flatten(input_shape=(28,28,1)), #1 - blanco y negro\r\n",
                "  tf.keras.layers.Dense(50, activation=tf.nn.relu),\r\n",
                "  tf.keras.layers.Dense(50, activation=tf.nn.relu),\r\n",
                "  tf.keras.layers.Dense(10, activation=tf.nn.softmax) #Para redes de clasificacion\r\n",
                "])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "source": [
                "modelo.compile(\r\n",
                "    optimizer='adam',\r\n",
                "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\r\n",
                "    metrics=['accuracy']\r\n",
                ")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "source": [
                "num_ej_entrenamiento = metadatos.splits[\"train\"].num_examples\r\n",
                "num_ej_pruebas = metadatos.splits[\"test\"].num_examples\r\n",
                "print(num_ej_entrenamiento)\r\n",
                "print(num_ej_pruebas)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "60000\n",
                        "10000\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "source": [
                "TAMANO_LOTE = 32\r\n",
                "\r\n",
                "#Shuffle y repeat hacen que los datos esten mezclados de manera aleatoria para que la red\r\n",
                "#no se vaya a aprender el orden de las cosas\r\n",
                "datos_entrenamiento = datos_entrenamiento.repeat().shuffle(num_ej_entrenamiento).batch(TAMANO_LOTE)\r\n",
                "datos_pruebas = datos_pruebas.batch(TAMANO_LOTE)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "source": [
                "import math\r\n",
                "\r\n",
                "#Entrenar\r\n",
                "historial = modelo.fit(datos_entrenamiento, epochs=5, steps_per_epoch= math.ceil(num_ej_entrenamiento/TAMANO_LOTE))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Train for 1875 steps\n",
                        "Epoch 1/5\n",
                        "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5219 - accuracy: 0.8167\n",
                        "Epoch 2/5\n",
                        "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3895 - accuracy: 0.8596\n",
                        "Epoch 3/5\n",
                        "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3551 - accuracy: 0.8711\n",
                        "Epoch 4/5\n",
                        "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3299 - accuracy: 0.8788\n",
                        "Epoch 5/5\n",
                        "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3160 - accuracy: 0.8846\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#plt.xlabel(\"# Epoca\")\r\n",
                "#plt.ylabel(\"Magnitud de p√©rdida\")\r\n",
                "#plt.plot(historial.history[\"loss\"])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#for imagenes_prueba, etiquetas_prueba in datos_pruebas.take(1):\r\n",
                "#  imagenes_prueba = imagenes_prueba.numpy()\r\n",
                "#  etiquetas_prueba = etiquetas_prueba.numpy()\r\n",
                "#  predicciones = modelo.predict(imagenes_prueba)\r\n",
                "#  \r\n",
                "#def graficar_imagen(i, arr_predicciones, etiquetas_reales, imagenes):\r\n",
                "#  arr_predicciones, etiqueta_real, img = arr_predicciones[i], etiquetas_reales[i], imagenes[i]\r\n",
                "#  plt.grid(False)\r\n",
                "#  plt.xticks([])\r\n",
                "#  plt.yticks([])\r\n",
                "  \r\n",
                "#  plt.imshow(img[...,0], cmap=plt.cm.binary)\r\n",
                "\r\n",
                "#  etiqueta_prediccion = np.argmax(arr_predicciones)\r\n",
                "#  if etiqueta_prediccion == etiqueta_real:\r\n",
                "#    color = 'blue'\r\n",
                "#  else:\r\n",
                "#    color = 'red'\r\n",
                "#  \r\n",
                "#  plt.xlabel(\"{} {:2.0f}% ({})\".format(nombres_clases[etiqueta_prediccion],\r\n",
                "#                                100*np.max(arr_predicciones),\r\n",
                "#                                nombres_clases[etiqueta_real]),\r\n",
                "#                                color=color)\r\n",
                "#  \r\n",
                "#def graficar_valor_arreglo(i, arr_predicciones, etiqueta_real):\r\n",
                "#  arr_predicciones, etiqueta_real = arr_predicciones[i], etiqueta_real[i]\r\n",
                "#  plt.grid(False)\r\n",
                "#  plt.xticks([])\r\n",
                "#  plt.yticks([])\r\n",
                "#  grafica = plt.bar(range(10), arr_predicciones, color=\"#777777\")\r\n",
                "#  plt.ylim([0, 1]) \r\n",
                "#  etiqueta_prediccion = np.argmax(arr_predicciones)\r\n",
                "  \r\n",
                "#  grafica[etiqueta_prediccion].set_color('red')\r\n",
                "#  grafica[etiqueta_real].set_color('blue')\r\n",
                "  \r\n",
                "#filas = 5\r\n",
                "#columnas = 5\r\n",
                "#num_imagenes = filas*columnas\r\n",
                "#plt.figure(figsize=(2*2*columnas, 2*filas))\r\n",
                "#for i in range(num_imagenes):\r\n",
                "#  plt.subplot(filas, 2*columnas, 2*i+1)\r\n",
                "#  graficar_imagen(i, predicciones, etiquetas_prueba, imagenes_prueba)\r\n",
                "#  plt.subplot(filas, 2*columnas, 2*i+2)\r\n",
                "#  graficar_valor_arreglo(i, predicciones, etiquetas_prueba)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#Guardar modelo\r\n",
                "#modelo.save('clasificador_ropa.h5')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#!pip install tensorflowjs"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#!mkdir archivos_salida"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#!tensorflowjs_converter --input_format keras clasificador_ropa.h5 archivos_salida/"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.6.13",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6.13 64-bit ('quast-env': conda)"
        },
        "interpreter": {
            "hash": "fe24404a8735380659f59ce132d8c3ef0e5a5db1fecddd7b482acd0926ba191b"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}